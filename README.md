# KICK
KICK: Korean Football In-game Conversation State Tracking Dataset for Dialogue and Turn Level Evaluation

<img width="1210" alt="Screen Shot 2024-10-01 at 2 03 15 PM" src="https://github.com/user-attachments/assets/b368139a-7574-4a44-af6a-a021f9a8bfe1">
Recent research in dialogue state tracking has made significant progress in tracking user goals through dialogue-level and turn-level approaches, but existing research primarily focused on predicting dialogue-level belief states. In this study, we present the KICK: Korean football In-game Conversation state tracKing dataset, which introduces a conversation-based approach. This approach leverages the roles of casters and commentators within the self-contained context of sports broadcasting to examine how utterances impact the belief state at both the dialogue-level and turn-level. Toward this end, we propose a task that aims to track the states of a specific time turn and understand conversations during the entire game. The proposed dataset comprises 228 games and 2463 events over one season, with a larger number of tokens per dialogue and turn, making it more challenging than existing datasets. Experiments revealed that the roles and interactions of casters and commentators are important for improving the zero-shot state tracking performance. By better understanding role-based utterances, we identify distinct approaches to the overall game process and events at specific turns.

## 1. Data Construction
<img width="883" alt="Screen Shot 2024-10-01 at 2 04 11 PM" src="https://github.com/user-attachments/assets/2186b30e-3922-4bfa-8d82-9e64a674951b">
The data construction part is omitted from this document.

## 2. LLM-based Inference

### Models Used

#### GPT-4o
- Model Version: gpt-4o-2024-05-13
- Model Documentation: [GPT-4o](https://platform.openai.com/docs/models/gpt-4o)
- Generation Parameters:
  - temperature: 1
  - top_p: 1

#### Gemma-2-9B-IT
- Version Info: No specific version; using the latest model as of 2024-09-25
- Model Documentation: [Gemma-2-9B-IT](https://huggingface.co/google/gemma-2-9b-it)
- Generation Parameters:
  - repetition_penalty: 1
  - temperature: 0.5
  - top_p: 0.3

#### Meta-Llama-3-8B
- Model Documentation: [Meta-Llama-3-8B](https://huggingface.co/meta-llama/Meta-Llama-3-8B)
- Generation Parameters:
  - temperature: 0.6
  - top_p: 0.3
  - max_len: 4096

### How to Run
The script to run inference using the models mentioned above is as follows. Before executing this script, it may be necessary to set up each modelâ€™s API key or endpoint.

```bash
./run_inference.sh
```

## 3. Post-processing of Inference Results

Post-processing the results generated by each model to make them suitable for evaluation. The script for post-processing can be run as follows:

```bash
./run_results_process.sh
```

## 4. Evaluation

Evaluate the performance of the models using the post-processed data. Running the evaluation script will generate a log file containing various performance metrics (JGA, TGA, SA, RSA, RGI) for both the full game and the first half of the game.

```bash
./eval.sh
```

## Additional Information

This code is used to evaluate the performance of specific machine learning models and requires setting up API keys for each model before actual use. Further details about the usage of each script and the format of input files required at each stage may also be needed.
